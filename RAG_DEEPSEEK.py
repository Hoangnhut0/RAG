import streamlit as st
import fitz  # PyMuPDF Ä‘á»ƒ trÃ­ch xuáº¥t vÄƒn báº£n tá»« PDF
import pytesseract
from pdf2image import convert_from_path
import qdrant_client
from qdrant_client.models import PointStruct, Distance, VectorParams
import os
import uuid
from sentence_transformers import SentenceTransformer
import cv2  # OpenCV Ä‘á»ƒ xá»­ lÃ½ áº£nh
from PIL import Image  # Pillow Ä‘á»ƒ xá»­ lÃ½ áº£nh
from fuzzywuzzy import fuzz  # So sÃ¡nh chuá»—i gáº§n Ä‘Ãºng
import nltk  # Thay tháº¿ spaCy Ä‘á»ƒ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn
import numpy as np
import requests  # Äá»ƒ gá»i API Ollama

# Táº£i tÃ i nguyÃªn punkt_tab náº¿u chÆ°a cÃ³
try:
    nltk.data.find('tokenizers/punkt_tab')
except LookupError:
    nltk.download('punkt_tab', quiet=True)

# ğŸ”¹ Khá»Ÿi táº¡o mÃ´ hÃ¬nh embedding
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# ğŸ”¹ Káº¿t ná»‘i Ä‘áº¿n Qdrant
qdrant = qdrant_client.QdrantClient("localhost", port=6333)
collection_name = "library_docs"

def ensure_collection_exists():
    collections = qdrant.get_collections()
    collection_names = [col.name for col in collections.collections]
    if collection_name not in collection_names:
        qdrant.create_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE),
        )
        st.success(f"âœ… Collection `{collection_name}` Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng!")

ensure_collection_exists()

# ğŸ“„ Tiá»n xá»­ lÃ½ hÃ¬nh áº£nh trÆ°á»›c OCR
def preprocess_image(image):
    gray = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)
    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)
    gray = cv2.fastNlMeansDenoising(gray, h=10)
    return Image.fromarray(gray)

# ğŸ”¹ HÃ m gá»i API Ollama DeepSeek R1
def call_ollama(prompt, model="deepseek-r1"):
    url = "http://localhost:11434/api/generate"
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }
    try:
        response = requests.post(url, json=payload)
        response.raise_for_status()
        result = response.json()
        return result.get("response", "KhÃ´ng thá»ƒ táº¡o cÃ¢u tráº£ lá»i.")
    except Exception as e:
        print(f"âŒ Lá»—i khi gá»i Ollama: {e}")
        return "KhÃ´ng thá»ƒ táº¡o cÃ¢u tráº£ lá»i."

# Sá»­a lá»—i chÃ­nh táº£ báº±ng Ollama
def correct_spelling_with_ollama(text):
    prompt = f"""
    VÄƒn báº£n sau cÃ³ thá»ƒ chá»©a lá»—i chÃ­nh táº£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh do trÃ­ch xuáº¥t tá»« OCR.
    HÃ£y sá»­a lá»—i chÃ­nh táº£ vÃ  tráº£ vá» vÄƒn báº£n Ä‘Ã£ Ä‘Æ°á»£c chá»‰nh sá»­a:
    "{text}"
    """
    return call_ollama(prompt)

# ğŸ“„ TrÃ­ch xuáº¥t vÄƒn báº£n tá»« PDF thÆ°á»ng vÃ  PDF scan
def extract_text_from_pdf(pdf_path):
    try:
        doc = fitz.open(pdf_path)
        text_content = []
        for page_num, page in enumerate(doc, start=1):
            text = page.get_text("text").strip()
            if text:
                text_content.append(f"{text}\n[Trang {page_num}]")
        return "\n".join(text_content) if text_content else extract_text_with_ocr(pdf_path)
    except Exception as e:
        st.error(f"âŒ Lá»—i khi Ä‘á»c PDF: {e}")
        return "KhÃ´ng cÃ³ ná»™i dung."

# Sá»­ dá»¥ng OCR vá»›i tiá»n xá»­ lÃ½ nÃ¢ng cao vÃ  sá»­a lá»—i chÃ­nh táº£
def extract_text_with_ocr(pdf_path):
    try:
        images = convert_from_path(pdf_path)
        text_content = []
        for i, img in enumerate(images):
            processed_img = preprocess_image(img)
            custom_config = r'--oem 3 --psm 6 -l eng+vie'
            raw_text = pytesseract.image_to_string(processed_img, config=custom_config).strip()
            if raw_text:
                corrected_text = correct_spelling_with_ollama(raw_text)
                text_content.append(f"{corrected_text}\n[Trang {i+1}]")
                print(f"ğŸ“œ VÄƒn báº£n sau khi sá»­a lá»—i chÃ­nh táº£ (Trang {i+1}):\n{corrected_text}\n{'='*50}")
        return "\n".join(text_content) if text_content else "KhÃ´ng cÃ³ ná»™i dung."
    except Exception as e:
        st.error(f"âŒ Lá»—i khi xá»­ lÃ½ OCR: {e}")
        return "KhÃ´ng cÃ³ ná»™i dung."

# ğŸ”¹ Chuyá»ƒn vÄƒn báº£n thÃ nh vector embedding
def generate_embedding(text):
    return embedding_model.encode(text).tolist() if text.strip() else [0.0] * 384

# ğŸ”¹ LÆ°u tÃ i liá»‡u vÃ o Qdrant
def store_document_in_qdrant(doc_id, text, metadata):
    vector = generate_embedding(text)
    metadata["text_content"] = text
    print(f"ğŸ“¦ VÄƒn báº£n cuá»‘i cÃ¹ng lÆ°u vÃ o Qdrant:\n{text}\n{'='*50}")
    qdrant.upsert(
        collection_name=collection_name,
        points=[PointStruct(id=doc_id, vector=vector, payload=metadata)]
    )

# ğŸ” TÃ¬m kiáº¿m tÃ i liá»‡u trong Qdrant
def search_documents(query):
    query_vector = generate_embedding(query)
    results = qdrant.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=10,
        with_payload=True
    )
    filtered_results = []
    for r in results:
        text = r.payload.get("text_content", "").lower()
        if fuzz.partial_ratio(query.lower(), text) > 70 or r.score >= 0.4:
            filtered_results.append(r)
    return filtered_results

# ğŸ“Œ TrÃ­ch xuáº¥t Ä‘oáº¡n vÄƒn báº£n vá»›i nltk
def extract_relevant_text(full_text, query, filename, context_size=300):
    query_lower = query.lower()
    sentences = nltk.sent_tokenize(full_text)
    for sent in sentences:
        if query_lower in sent.lower():
            start_idx = full_text.lower().find(sent.lower())
            if start_idx == -1:
                continue
            start = max(0, start_idx - context_size // 2)
            end = min(len(full_text), start_idx + len(sent) + context_size // 2)
            relevant_text = full_text[start:end]
            page_number = "KhÃ´ng rÃµ trang"
            text_before = full_text[:end]
            pages = [line for line in text_before.split("\n") if "[Trang " in line]
            if pages:
                last_page_line = pages[-1]
                page_number = last_page_line.split("[Trang ")[-1].replace("]", "").strip()
            return f"{relevant_text}...", page_number
    return None, "KhÃ´ng rÃµ trang"

# ğŸ¤– Xá»­ lÃ½ vá»›i Ollama DeepSeek R1 (Pháº§n tráº£ lá»i chÃ­nh tá»« Ollama)
def process_with_ollama(query, filename=None, context=None):
    if context:
        prompt = f"""
        NgÆ°á»i dÃ¹ng Ä‘ang tÃ¬m kiáº¿m thÃ´ng tin trong tÃ i liá»‡u: `{filename}`
        Truy váº¥n: "{query}"
        Ná»™i dung liÃªn quan tá»« tÃ i liá»‡u:
        {context}
        HÃ£y diá»…n giáº£i láº¡i thÃ´ng tin má»™t cÃ¡ch dá»… hiá»ƒu vÃ  cung cáº¥p ná»™i dung tá»‘i Æ°u nháº¥t.
        """
    else:
        prompt = f'NgÆ°á»i dÃ¹ng Ä‘ang há»i: "{query}" KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u phÃ¹ há»£p.'
    return call_ollama(prompt)  # Pháº§n tráº£ lá»i tá»« Ollama Ä‘Æ°á»£c tráº£ vá» Ä‘Ã¢y

# ğŸ¯ Giao diá»‡n Streamlit
def main():
    st.title("ğŸ“š ThÆ° viá»‡n sá»‘ thÃ´ng minh")
    
    uploaded_file = st.file_uploader("ğŸ“¤ Táº£i lÃªn tÃ i liá»‡u PDF", type=["pdf"])
    if uploaded_file and st.button("ğŸ“¥ LÆ°u tÃ i liá»‡u"):
        pdf_path = f"uploads/{uploaded_file.name}"
        os.makedirs("uploads", exist_ok=True)
        with open(pdf_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        text = extract_text_from_pdf(pdf_path)
        metadata = {"filename": uploaded_file.name}
        doc_id = str(uuid.uuid4())
        store_document_in_qdrant(doc_id, text, metadata)
        st.success(f"âœ… TÃ i liá»‡u `{uploaded_file.name}` Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trá»¯ thÃ nh cÃ´ng!")

    query = st.text_input("ğŸ” Nháº­p tá»« khÃ³a tÃ¬m kiáº¿m")
    if st.button("ğŸ” TÃ¬m kiáº¿m"):
        results = search_documents(query)
        
        if results:
            for result in results:
                filename = result.payload.get("filename", "KhÃ´ng cÃ³ tÃªn tÃ i liá»‡u")
                full_text = result.payload.get("text_content", "")
                similarity_score = result.score
                relevant_text, page_number = extract_relevant_text(full_text, query, filename)
                
                if relevant_text:
                    st.markdown(
                        f"ğŸ“„ **TÃ i liá»‡u:** {filename} - ğŸ“Œ **Trang:** {page_number} - "
                        f"ğŸ“Š **Äiá»ƒm tÆ°Æ¡ng Ä‘á»“ng:** {similarity_score:.4f}"
                    )
                    st.markdown(f"ğŸ“Œ **Ná»™i dung trÃ­ch xuáº¥t:**\n\n{relevant_text}")
                    # Láº¥y vÃ  hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i tá»« Ollama
                    refined_answer = process_with_ollama(query, filename, relevant_text)
                    st.markdown(f"ğŸ¤– **Tráº£ lá»i tá»« Ollama:**\n\n{refined_answer}")  # Pháº§n tráº£ lá»i Ä‘Æ°á»£c hiá»ƒn thá»‹ á»Ÿ Ä‘Ã¢y
        else:
            # TrÆ°á»ng há»£p khÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u, Ollama váº«n tráº£ lá»i dá»±a trÃªn truy váº¥n
            refined_answer = process_with_ollama(query)
            st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u phÃ¹ há»£p.")
            st.markdown(f"ğŸ¤– **Tráº£ lá»i tá»« Ollama:**\n\n{refined_answer}")  # Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i khi khÃ´ng cÃ³ tÃ i liá»‡u

if __name__ == "__main__":
    main()